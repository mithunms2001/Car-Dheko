{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42c8bd4-ca79-44e6-a46d-d1957c3d8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\H'\n",
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_23420\\1000929989.py:13: SyntaxWarning: invalid escape sequence '\\H'\n",
      "  df = pd.read_csv(\"C:\\\\Users\\Home\\\\Car_dekho\\\\Car_Dheko\\\\final_cleaned_car_dheko.csv\", low_memory=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"C:\\\\Users\\Home\\\\Car_dekho\\\\Car_Dheko\\\\final_cleaned_car_dheko.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5107b6f5-e569-4369-b5f8-cdd6232669fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ft', 'bt', 'km', 'transmission', 'ownerNo', 'model',\n",
       "       'centralVariantId', 'Insurance Validity', 'Seats',\n",
       "       'Engine Displacement', 'Mileage', 'Max Power', 'Torque', 'Wheel Size',\n",
       "       'Color', 'Engine Type', 'Max Power_rpm', 'Max Torque', 'No of Cylinder',\n",
       "       'Value Configuration', 'Fuel Supply System', 'Length', 'Width',\n",
       "       'Height', 'Wheel Base', 'Front Tread', 'Kerb Weight', 'Gross Weight',\n",
       "       'Gear Box', 'Drive Type', 'Steering Type', 'Turning Radius',\n",
       "       'Front Brake Type', 'Top Speed', 'Acceleration', 'Tyre Type',\n",
       "       'Alloy Wheel Size', 'Cargo Volume', 'City', 'Car_age', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121f1691-742f-4de9-9e14-393abdb21add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select required columns\n",
    "required_columns = ['ft', 'bt', 'km', 'transmission', 'model', 'Insurance Validity', 'Seats', \n",
    "                    'Engine Displacement', 'Mileage', 'Max Power', 'Torque', 'No of Cylinder', 'Length', 'Width', \n",
    "                    'Height', 'Kerb Weight','Drive Type', 'Cargo Volume', 'City', 'Car_age', 'price']\n",
    "\n",
    "df = df[required_columns]\n",
    "\n",
    "\n",
    "# Replace inf with NaN and fill NaNs with mean\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e570aa-7620-4f89-884b-95d134f8a509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5549, 20)\n",
      "y_train shape: (5549,)\n",
      "X_test shape: (1388, 20)\n",
      "y_test shape: (1388,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(['price'], axis=1)  # Features\n",
    "y = df['price']  # Target variable\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the splits\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289a37e2-b859-4129-a8af-a42080b3f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression - Model Fit and Predict\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, y_train)\n",
    "y_pred_lin = lin_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0356afb-5086-4af6-8fb6-9e93bf03ca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "# 2. Random Forest Regressor - GridSearchCV and Model Fit/Predict\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, verbose=2, scoring='r2')\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54eedac5-df81-4941-b4b3-18322926cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    }
   ],
   "source": [
    "# 3. Gradient Boosting Regressor - GridSearchCV and Model Fit/Predict\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, cv=3, n_jobs=-1, verbose=2, scoring='r2')\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "y_pred_gb = best_gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0250c458-0ad8-4c1d-86ce-b5ca61a1d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    }
   ],
   "source": [
    "# 4. Decision Tree Regressor - GridSearchCV and Model Fit/Predict\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "dt_grid_search = GridSearchCV(estimator=dt_model, param_grid=dt_param_grid, cv=3, n_jobs=-1, verbose=2, scoring='r2')\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "best_dt_model = dt_grid_search.best_estimator_\n",
    "y_pred_dt = best_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f10f12-a085-4a70-a7ac-78f03058fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating all models:\n",
      "Linear Regression Evaluation:\n",
      "MAE: 163915.13\n",
      "MSE: 100448727118.82\n",
      "R²: 0.62\n",
      "\n",
      "Random Forest Regressor Evaluation:\n",
      "MAE: 69499.99\n",
      "MSE: 15206757204.99\n",
      "R²: 0.94\n",
      "\n",
      "Gradient Boosting Regressor Evaluation:\n",
      "MAE: 65066.98\n",
      "MSE: 12250169423.88\n",
      "R²: 0.95\n",
      "\n",
      "Decision Tree Regressor Evaluation:\n",
      "MAE: 93461.26\n",
      "MSE: 26199562383.37\n",
      "R²: 0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models\n",
    "def evaluate_model(model_name, y_test, y_pred):\n",
    "    print(f\"{model_name} Evaluation:\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"R²: {r2_score(y_test, y_pred):.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Evaluating all models:\")\n",
    "evaluate_model(\"Linear Regression\", y_test, y_pred_lin)\n",
    "evaluate_model(\"Random Forest Regressor\", y_test, y_pred_rf)\n",
    "evaluate_model(\"Gradient Boosting Regressor\", y_test, y_pred_gb)\n",
    "evaluate_model(\"Decision Tree Regressor\", y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f612e2fc-6b44-4357-8a80-f1d59cebc177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics:\n",
      "Linear Regression - R²: 0.62, MSE: 100448727118.82, MAE: 163915.13\n",
      "Random Forest Regressor - R²: 0.94, MSE: 15206757204.99, MAE: 69499.99\n",
      "Gradient Boosting Regressor - R²: 0.95, MSE: 12250169423.88, MAE: 65066.98\n",
      "Decision Tree Regressor - R²: 0.90, MSE: 26199562383.37, MAE: 93461.26\n",
      "\n",
      "The best model is Gradient Boosting Regressor with R²: 0.95\n",
      "Best Model - MSE: 12250169423.88, MAE: 65066.98\n"
     ]
    }
   ],
   "source": [
    "# Calculate R² scores for all models\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "# Calculate MSE and MAE for all models\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "mae_lin = mean_absolute_error(y_test, y_pred_lin)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "\n",
    "# Choose the best model based on R² score\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_r2 = max(r2_lin, r2_rf, r2_gb, r2_dt)\n",
    "\n",
    "if best_r2 == r2_lin:\n",
    "    best_model = lin_model\n",
    "    best_model_name = \"Linear Regression\"\n",
    "    best_mse = mse_lin\n",
    "    best_mae = mae_lin\n",
    "elif best_r2 == r2_rf:\n",
    "    best_model = best_rf_model\n",
    "    best_model_name = \"Random Forest Regressor\"\n",
    "    best_mse = mse_rf\n",
    "    best_mae = mae_rf\n",
    "elif best_r2 == r2_gb:\n",
    "    best_model = best_gb_model\n",
    "    best_model_name = \"Gradient Boosting Regressor\"\n",
    "    best_mse = mse_gb\n",
    "    best_mae = mae_gb\n",
    "else:\n",
    "    best_model = best_dt_model\n",
    "    best_model_name = \"Decision Tree Regressor\"\n",
    "    best_mse = mse_dt\n",
    "    best_mae = mae_dt\n",
    "\n",
    "# Display all models' results\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"Linear Regression - R²: {r2_lin:.2f}, MSE: {mse_lin:.2f}, MAE: {mae_lin:.2f}\")\n",
    "print(f\"Random Forest Regressor - R²: {r2_rf:.2f}, MSE: {mse_rf:.2f}, MAE: {mae_rf:.2f}\")\n",
    "print(f\"Gradient Boosting Regressor - R²: {r2_gb:.2f}, MSE: {mse_gb:.2f}, MAE: {mae_gb:.2f}\")\n",
    "print(f\"Decision Tree Regressor - R²: {r2_dt:.2f}, MSE: {mse_dt:.2f}, MAE: {mae_dt:.2f}\")\n",
    "\n",
    "# Display best model's results\n",
    "print(f\"\\nThe best model is {best_model_name} with R²: {best_r2:.2f}\")\n",
    "print(f\"Best Model - MSE: {best_mse:.2f}, MAE: {best_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae1bf41e-eb48-4d6c-872b-f878c4e1b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "R2 Score: 0.9549037744153694\n",
      "RMSE: 108627.51272649184\n",
      "Model saved to C:\\Users\\Home\\Car_dekho\\Car_Dheko\\gradient_boosting_model.pkl using pickle.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the dataframe 'df' is already preprocessed\n",
    "\n",
    "# Feature Engineering: Calculate km_per_year and drop 'km'\n",
    "df['km_per_year'] = df['km'] / df['Car_age'].replace(0, np.nan)\n",
    "df.drop(columns=['km'], inplace=True)\n",
    "\n",
    "# Additional Feature Engineering\n",
    "df['power_to_weight'] = df['Max Power'] / df['Kerb Weight']  # Power-to-Weight Ratio\n",
    "df['engine_size_per_cylinder'] = df['Engine Displacement'] / df['No of Cylinder'].replace(0, np.nan)  # Size per Cylinder\n",
    "df['torque_to_power'] = df['Torque'] / df['Max Power'].replace(0, np.nan)  # Torque-to-Power Ratio\n",
    "df['volume'] = df['Length'] * df['Width'] * df['Height']  # Volume of the Car\n",
    "\n",
    "# Replace inf with NaN and fill NaNs with mean\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "required_columns = ['ft', 'bt', 'km', 'transmission', 'model', 'Insurance Validity', 'Seats', \n",
    "                    'Engine Displacement', 'Mileage', 'Max Power', 'Torque', 'No of Cylinder', 'Length', 'Width', \n",
    "                    'Height', 'Kerb Weight','Drive Type', 'Cargo Volume', 'City', 'Car_age', 'price', 'km_per_year', \n",
    "                   'power_to_weight', 'engine_size_per_cylinder', 'torque_to_power', 'volume']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(df.drop(['price'], axis=1))  # Features\n",
    "y = df['price']  # Target variable\n",
    "\n",
    "# Step 3: Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Model Training with Hyperparameter Tuning\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Model Evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Define the output folder and file path\n",
    "output_dir = \"C:\\\\Users\\\\Home\\\\Car_dekho\\\\Car_Dheko\"\n",
    "output_path = os.path.join(output_dir, \"gradient_boosting_model.pkl\")\n",
    "\n",
    "# Automatically create the folder if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"Model saved to {output_path} using pickle.\")\n",
    "\n",
    "# To load the model later:\n",
    "# with open(output_path, 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88233d4e-9d29-4cff-87e6-390fd8b46082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
